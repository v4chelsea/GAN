{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"GAN.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPst1c9ZCgGl6LgIreso7hU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"uvKMFQ9PISlB"},"source":["# GAN: Generative Adversarial Networks"]},{"cell_type":"code","metadata":{"id":"jKvPIi81A6Yb"},"source":["import torch\n","import torch.nn as nn\n","\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2oPhlCHHCccV"},"source":["latent_dim = 100\n","\n","# 생성자(Generator) 클래스 정의\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","\n","        # 하나의 블록(block) 정의\n","        def block(input_dim, output_dim, normalize=True):\n","            layers = [nn.Linear(input_dim, output_dim)]\n","            if normalize:\n","                # 배치 정규화(batch normalization) 수행(차원 동일)\n","                layers.append(nn.BatchNorm1d(output_dim, 0.8))\n","            layers.append(nn.LeakyReLU(0.1, inplace=True))\n","            return layers\n","\n","        # 생성자 모델은 연속적인 여러 개의 블록을 가짐\n","        self.model = nn.Sequential(\n","            *block(latent_dim, 128, normalize=True),\n","            *block(128, 256),\n","            *block(256, 512),\n","            *block(512, 1024),\n","            nn.Linear(1024, 1 * 28 * 28),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, z):\n","        img = self.model(z)\n","        img = img.view(img.size(0), 1, 28, 28)\n","        return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MyFRlk8ZDedK"},"source":["# 판별자(Discriminator) 클래스 정의\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","\n","        # MLP 형태\n","        self.model = nn.Sequential(\n","            nn.Linear(1 * 28 * 28, 512),\n","            nn.LeakyReLU(0.1, inplace=True),\n","            nn.Linear(512, 256),\n","            nn.LeakyReLU(0.1, inplace=True),\n","            nn.Linear(256, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    # 이미지에 대한 판별 결과를 반환\n","    def forward(self, img):\n","        flattened = img.view(img.size(0), -1)\n","        output = self.model(flattened)\n","\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISmTizTIVxKu"},"source":["class MNIST_DataSet(torch.utils.data.Dataset):\n","    # 인자를 받아 인스턴스 변수를 초기화 \n","    # image_list - 이미지 전체 리스트\n","    def __init__(self, image_list, transform=None):\n","        super().__init__()\n","        self.image_list = image_list\n","        self.transform = transform\n","\n","    # 데이터 셋의 길이를 리턴한다.\n","    def __len__(self):\n","        return len(self.image_list)\n","    \n","    # 학습 이미지를 리턴한다.\n","    def __getitem__(self, idx):\n","        image = self.image_list[idx]\n","\n","        if self.transform:\n","          image = self.transform(image)\n","\n","        return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zj2wxolwEFPp"},"source":["transform = transforms.Compose([transforms.ToTensor(),                                \n","                                transforms.Resize(28),\n","                                transforms.Normalize([0.5], [0.5])])\n","\n","# GAN은 Test용 Dataset을 별도로 받을 필요가 없음\n","train_dataset = datasets.MNIST(root=\"./dataset\", \n","                               train=True, \n","                               download=True,\n","                               transform=transform)\n","\n","train = MNIST_DataSet(train_dataset.data.numpy(), transform=transform)\n","\n","imageloader = torch.utils.data.DataLoader(train, \n","                                          batch_size=1024, \n","                                          shuffle=True, \n","                                          num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7vg-XaNbEokY"},"source":["# 생성자(generator)와 판별자(discriminator) 초기화\n","generator = Generator()\n","discriminator = Discriminator()\n","\n","# generator, discriminator를 cuda로 올린다\n","generator.cuda()\n","discriminator.cuda()\n","\n","# 손실 함수(loss function) : Binary Cross Entropy Loss ( 진짜, 가짜 판별 : 이진 분류 )\n","# loss function을 cuda로 올린다\n","adversarial_loss = nn.BCELoss()\n","adversarial_loss.cuda()\n","\n","# 학습률(learning rate) 설정\n","lr = 0.0002\n","\n","# 생성자와 판별자를 위한 최적화 함수\n","optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n","optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5z5lpQAz12D","executionInfo":{"status":"ok","timestamp":1637232756648,"user_tz":-540,"elapsed":7,"user":{"displayName":"김대정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02576069035932629071"}},"outputId":"1dfccf5f-1ddd-4c43-ea32-013093b12ebf"},"source":["generator"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Generator(\n","  (model): Sequential(\n","    (0): Linear(in_features=100, out_features=128, bias=True)\n","    (1): BatchNorm1d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n","    (3): Linear(in_features=128, out_features=256, bias=True)\n","    (4): BatchNorm1d(256, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): LeakyReLU(negative_slope=0.1, inplace=True)\n","    (6): Linear(in_features=256, out_features=512, bias=True)\n","    (7): BatchNorm1d(512, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): LeakyReLU(negative_slope=0.1, inplace=True)\n","    (9): Linear(in_features=512, out_features=1024, bias=True)\n","    (10): BatchNorm1d(1024, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): LeakyReLU(negative_slope=0.1, inplace=True)\n","    (12): Linear(in_features=1024, out_features=784, bias=True)\n","    (13): Tanh()\n","  )\n",")"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CK25wkw6z30q","executionInfo":{"status":"ok","timestamp":1637232756648,"user_tz":-540,"elapsed":6,"user":{"displayName":"김대정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02576069035932629071"}},"outputId":"6099675d-93ae-4a16-daeb-b5658da1384c"},"source":["discriminator"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discriminator(\n","  (model): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n","    (2): Linear(in_features=512, out_features=256, bias=True)\n","    (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","    (4): Linear(in_features=256, out_features=1, bias=True)\n","    (5): Sigmoid()\n","  )\n",")"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"YzKcTPPca715"},"source":["def plot_images(images):\n","    images = images.cpu()\n","    fig = plt.figure(figsize=(20, 20))\n","\n","    for idx, image in enumerate(images):\n","        # 1, 28, 28 => 28, 28\n","        image = torch.squeeze(image)\n","        ax = fig.add_subplot(3, 3, idx+1)\n","        ax.imshow(image)\n","\n","    fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPxCdx-ECSoO","outputId":"fa4c27c8-32cb-46f6-819a-c9804cb8f7a2"},"source":["import time\n","\n","n_epochs = 200 # 학습의 횟수(epoch) 설정\n","sample_interval = 100 # 몇 번의 배치(batch)마다 결과를 출력할 것인지 설정\n","start_time = time.time()\n","hist = {'d_loss' : [], 'g_loss' : []}\n","\n","for epoch in range(n_epochs):\n","    for i, imgs in enumerate(imageloader):\n","\n","        # 진짜(real) 이미지와 가짜(fake) 이미지에 대한 정답 레이블 생성 (cuda로)\n","        real = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(1.0) # 진짜(real): 1\n","        fake = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(0.0) # 가짜(fake): 0\n","\n","        real_imgs = imgs.cuda()\n","\n","        \"\"\" 생성자(generator)를 학습합니다. \"\"\"\n","        optimizer_G.zero_grad()\n","\n","        # 랜덤 노이즈(noise) 샘플링 (cuda로)\n","        z = torch.normal(mean=0, std=1, size=(imgs.shape[0], latent_dim)).cuda()\n","\n","        # 이미지 생성\n","        generated_imgs = generator(z)\n","\n","        # 생성자(generator)의 손실(loss) 값 계산\n","        g_loss = adversarial_loss(discriminator(generated_imgs), real)\n","\n","        # 생성자(generator) 업데이트\n","        g_loss.backward()\n","        optimizer_G.step()\n","\n","        \"\"\" 판별자(discriminator)를 학습합니다. \"\"\"\n","        optimizer_D.zero_grad()\n","\n","        # 판별자(discriminator)의 손실(loss) 값 계산\n","        real_loss = adversarial_loss(discriminator(real_imgs), real)\n","        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)\n","        d_loss = (real_loss + fake_loss) / 2\n","\n","        # 판별자(discriminator) 업데이트\n","        d_loss.backward()\n","        optimizer_D.step()\n","\n","        done = epoch * len(imageloader) + i\n","        if done % sample_interval == 0:\n","            plot_images(generated_imgs.data[:9])\n","            # 생성된 이미지 중에서 25개만 선택하여 5 X 5 격자 이미지에 출력\n","            # save_image(generated_imgs.data[:25], f\"{done}.png\", nrow=5, normalize=True)\n","\n","    # 하나의 epoch이 끝날 때마다 로그(log) 출력, history에 loss값 저장\n","    print(f\"[Epoch {epoch + 1}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")\n","    \n","    hist['d_loss'].append(d_loss.item())\n","    hist['g_loss'].append(g_loss.item())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Epoch 1/200] [D loss: 0.542586] [G loss: 0.629575] [Elapsed time: 3.14s]\n","[Epoch 2/200] [D loss: 0.524990] [G loss: 0.733642] [Elapsed time: 6.25s]\n","[Epoch 3/200] [D loss: 0.563144] [G loss: 0.756645] [Elapsed time: 9.32s]\n","[Epoch 4/200] [D loss: 0.495023] [G loss: 1.636221] [Elapsed time: 12.38s]\n","[Epoch 5/200] [D loss: 0.427246] [G loss: 0.765303] [Elapsed time: 15.35s]\n","[Epoch 6/200] [D loss: 0.471336] [G loss: 0.979601] [Elapsed time: 18.41s]\n","[Epoch 7/200] [D loss: 0.504689] [G loss: 1.486079] [Elapsed time: 21.45s]\n","[Epoch 8/200] [D loss: 0.411939] [G loss: 0.995320] [Elapsed time: 24.46s]\n","[Epoch 9/200] [D loss: 0.465572] [G loss: 1.172309] [Elapsed time: 27.51s]\n","[Epoch 10/200] [D loss: 0.542683] [G loss: 1.625595] [Elapsed time: 30.50s]\n","[Epoch 11/200] [D loss: 0.380779] [G loss: 0.961354] [Elapsed time: 33.52s]\n","[Epoch 12/200] [D loss: 0.482408] [G loss: 1.112660] [Elapsed time: 36.61s]\n","[Epoch 13/200] [D loss: 0.479489] [G loss: 1.615893] [Elapsed time: 39.69s]\n","[Epoch 14/200] [D loss: 0.400205] [G loss: 1.232550] [Elapsed time: 42.78s]\n","[Epoch 15/200] [D loss: 0.342372] [G loss: 1.101072] [Elapsed time: 45.88s]\n","[Epoch 16/200] [D loss: 0.424819] [G loss: 0.709997] [Elapsed time: 48.95s]\n","[Epoch 17/200] [D loss: 0.290111] [G loss: 1.449613] [Elapsed time: 52.00s]\n","[Epoch 18/200] [D loss: 0.333218] [G loss: 1.135538] [Elapsed time: 54.99s]\n","[Epoch 19/200] [D loss: 0.419203] [G loss: 1.137614] [Elapsed time: 58.05s]\n","[Epoch 20/200] [D loss: 0.331074] [G loss: 1.570577] [Elapsed time: 61.06s]\n","[Epoch 21/200] [D loss: 0.302372] [G loss: 1.823234] [Elapsed time: 64.09s]\n","[Epoch 22/200] [D loss: 0.393941] [G loss: 0.951683] [Elapsed time: 67.15s]\n","[Epoch 23/200] [D loss: 0.501215] [G loss: 1.702282] [Elapsed time: 70.26s]\n","[Epoch 24/200] [D loss: 0.330573] [G loss: 1.202532] [Elapsed time: 73.36s]\n","[Epoch 25/200] [D loss: 0.467209] [G loss: 1.895334] [Elapsed time: 76.46s]\n","[Epoch 26/200] [D loss: 0.309334] [G loss: 1.064935] [Elapsed time: 79.61s]\n","[Epoch 27/200] [D loss: 0.336486] [G loss: 1.012455] [Elapsed time: 82.71s]\n","[Epoch 28/200] [D loss: 0.421062] [G loss: 2.637130] [Elapsed time: 85.89s]\n","[Epoch 29/200] [D loss: 0.329759] [G loss: 1.517881] [Elapsed time: 88.91s]\n","[Epoch 30/200] [D loss: 0.359820] [G loss: 2.248257] [Elapsed time: 91.91s]\n","[Epoch 31/200] [D loss: 0.901372] [G loss: 0.208765] [Elapsed time: 94.96s]\n","[Epoch 32/200] [D loss: 0.176739] [G loss: 2.835612] [Elapsed time: 97.95s]\n","[Epoch 33/200] [D loss: 0.309968] [G loss: 1.029771] [Elapsed time: 100.99s]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch 34/200] [D loss: 0.331809] [G loss: 1.866219] [Elapsed time: 104.12s]\n","[Epoch 35/200] [D loss: 0.287388] [G loss: 1.548493] [Elapsed time: 107.14s]\n","[Epoch 36/200] [D loss: 0.244702] [G loss: 1.278029] [Elapsed time: 110.21s]\n","[Epoch 37/200] [D loss: 0.310319] [G loss: 1.287450] [Elapsed time: 113.20s]\n","[Epoch 38/200] [D loss: 0.414342] [G loss: 3.272338] [Elapsed time: 116.28s]\n","[Epoch 39/200] [D loss: 0.291906] [G loss: 1.267127] [Elapsed time: 119.39s]\n","[Epoch 40/200] [D loss: 0.316152] [G loss: 1.353804] [Elapsed time: 122.40s]\n","[Epoch 41/200] [D loss: 0.270755] [G loss: 1.345102] [Elapsed time: 125.52s]\n","[Epoch 42/200] [D loss: 0.336491] [G loss: 1.006948] [Elapsed time: 128.45s]\n","[Epoch 43/200] [D loss: 0.277623] [G loss: 3.629857] [Elapsed time: 131.51s]\n","[Epoch 44/200] [D loss: 0.272414] [G loss: 2.946200] [Elapsed time: 134.51s]\n","[Epoch 45/200] [D loss: 0.197941] [G loss: 1.604400] [Elapsed time: 137.69s]\n","[Epoch 46/200] [D loss: 0.373669] [G loss: 0.821809] [Elapsed time: 140.80s]\n","[Epoch 47/200] [D loss: 0.250753] [G loss: 2.190129] [Elapsed time: 143.79s]\n","[Epoch 48/200] [D loss: 0.407890] [G loss: 0.711962] [Elapsed time: 146.87s]\n","[Epoch 49/200] [D loss: 0.274821] [G loss: 1.655248] [Elapsed time: 149.79s]\n","[Epoch 50/200] [D loss: 0.230214] [G loss: 1.381422] [Elapsed time: 152.77s]\n","[Epoch 51/200] [D loss: 0.182696] [G loss: 1.758180] [Elapsed time: 155.78s]\n","[Epoch 52/200] [D loss: 0.204774] [G loss: 2.113579] [Elapsed time: 158.74s]\n","[Epoch 53/200] [D loss: 0.484887] [G loss: 0.699891] [Elapsed time: 161.74s]\n","[Epoch 54/200] [D loss: 0.179537] [G loss: 1.725328] [Elapsed time: 164.68s]\n","[Epoch 55/200] [D loss: 0.469765] [G loss: 0.628988] [Elapsed time: 167.71s]\n","[Epoch 56/200] [D loss: 0.260614] [G loss: 1.848261] [Elapsed time: 170.73s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"Fjw_dGNI2_xZ"},"source":["학습속도 : Epoch당 약 15 ~ 20초 (GPU기준)"]},{"cell_type":"code","metadata":{"id":"hpjZOF2x3ETE"},"source":["def history(hist):\n","  fig = plt.figure(figsize=(20, 10))\n","  ax = fig.add_subplot(1, 2, 1)\n","  ax.plot(range(1, n_epochs+1), hist['d_loss'], color=\"red\", label=\"d loss\")\n","  ax.set_title(\"D Loss\")\n","  ax.legend()\n","\n","  ax = fig.add_subplot(1, 2, 2)\n","  ax.plot(range(1, n_epochs+1), hist['g_loss'], color=\"blue\", label=\"g loss\")\n","  ax.set_title(\"G Loss\")\n","  ax.legend()\n","\n","  fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x3tCpbzeC2UT"},"source":["history(hist)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-6a0icVYq2x-"},"source":["# 랜덤 노이즈(noise) 샘플링 (cuda로)\n","z = torch.normal(mean=0, std=1, size=(imgs.shape[0], latent_dim)).cuda()\n","\n","# 이미지 생성\n","generated_imgs = generator(z)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jx8KNDSEq5eX"},"source":["plot_images(generated_imgs.data[:9])"],"execution_count":null,"outputs":[]}]}